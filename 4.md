## 4. Maximum likelihood estimate (MLE)

### 4.1 MLE (part 1)
- Image classification 으로 생각해서 저 식을 $p(y|x,D) = \integral p(y|x, D, \theta)p(\theta|x, D) d\theta$ 로 생각하면 $p(y|x,D)$ 는 트레이닝 데이터 $D$ 에 기반하여 판단할 때, $x$ 라는 이미지의 클래스 레이블이 $y$ 일 확률이죠. 즉 테스트 데이터 포인트 $x$ 를 어떻게 분류하는게 확률적으로 맞는지, 우리가 궁극적으로 계산하고 싶은거죠.  $\integral$ 의 의미는, 데이터 $D$ 및 $x$ 가 추출되는 파라미터가 변수 $θ$ 일 때, 각각의 확률을 곱의 법칙으로 계산하여 더한거죠. 이렇게 보면 $p(y|x, D, \theta)$는 $\theta$가 정해져있을 때 계산이니 그냥 하면 되고 $p(\theta|x, D)$는 데이터 $x, D$가 어떤 $\theta$를 생성한 건지 묻는건데 알 수가 없어 보입니다. 
### 4.2 MLE (part 2)
- 제가 이해한 바로는 기본적으로 $p(y|x, D)$가 구하기 어려워서 우회하는 방법들이 ML의 주 테크닉인데 그 중 MLE는 $\theta$로 parametrize한 $p_{\theta}(y|x)$에 대해 $\theta_{MLE}$를 구해서 $p_{theta_{MLE}}(y|x)$ $p(y|x, D)$를 대신하려는 접근입니다. 
- 강의에서 wrong objective? - disgards loss에 해당하는 예시가 뭐가 있을까요? 
