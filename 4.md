## 4. Maximum likelihood estimate (MLE)

### 4.1 MLE (part 1)
- Image classification 으로 생각해서 저 식을 $p(y|x,D) = \int p(y|x, D, \theta)p(\theta|x, D) d\theta$ 로 생각하면 $p(y|x,D)$ 는 트레이닝 데이터 $D$ 에 기반하여 판단할 때, $x$ 라는 이미지의 클래스 레이블이 $y$ 일 확률이죠. 즉 테스트 데이터 포인트 $x$ 를 어떻게 분류하는게 확률적으로 맞는지, 우리가 궁극적으로 계산하고 싶은거죠.  $\int$ 의 의미는, 데이터 $D$ 및 $x$ 가 추출되는 파라미터가 변수 $θ$ 일 때, 각각의 확률을 곱의 법칙으로 계산하여 더한거죠. 이렇게 보면 $p(y|x, D, \theta)$는 $\theta$가 정해져있을 때 계산이니 그냥 하면 되고 $p(\theta|x, D)$는 데이터 $x, D$가 어떤 $\theta$를 생성한 건지 묻는건데 알 수가 없어 보입니다. 
### 4.2 MLE (part 2)
- 제가 이해한 바로는 기본적으로 $p(y|x, D)$가 구하기 어려워서 우회하는 방법들이 ML의 주 테크닉인데 그 중 MLE는 $\theta$로 parametrize한 $p_{\theta}(y|x)$에 대해 $\theta_{MLE}$를 구해서 $p_{\theta_{MLE}}(y|x)$ $p(y|x, D)$를 대신하려는 접근입니다. 
- 강의에서 wrong objective? - disgards loss에 해당하는 예시가 뭐가 있을까요? 
### 4.3 MLE for univariate Gaussian mean
- constraint maximization이 등장하는데 문제 푸는 방식이 다른가요? 제가 아는 maximization은 concave 확인하고 미분해서 극점 확인하는게 다 입니다ㅠ
	- 일반적으로 constraint 가 있는 최적화 문제가 더 풀기 어려워요. 그리고 constraint 가 있던 없던 최적화문제를 푸는 방법이 딱 정해져 있는게 아니고 일반적으로 어려워요. 그래서 convex optimization 이라는 분야가 있는거죠.
	- Nonconvex constrainted 최적화 문제를 푸는 방법 중에 Lagrange multiplier 를 이용하는 방법이 있는데 이게 convex 문제로 바꿔주는 효과가 있어요.
	- [Lagrangian duality - Stanford Univ.](https://cs.stanford.edu/people/davidknowles/lagrangian_duality.pdf)
	- [Convex optimization - cmu lecture](http://www.stat.cmu.edu/~ryantibs/convexopt/)
	- [Convex optimization - Stanford lecture](https://lagunita.stanford.edu/courses/Engineering/CVX101/Winter2014/about)
### 4.4~5 MLE for a PMF on a finite set
